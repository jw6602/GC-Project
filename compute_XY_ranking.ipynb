{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute XY-Rankings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "\n",
    "from PMFG_mod import PMFG\n",
    "\n",
    "from time import time\n",
    "import timeit\n",
    "\n",
    "#%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1006 rows and 485 columns in the dataset.\n",
      "Data timeperiod covers: 2016-01-04 00:00:00 to 2019-12-31 00:00:00\n"
     ]
    }
   ],
   "source": [
    "# S&P constituents return data\n",
    "\n",
    "log_returns_df = pd.read_excel(\"data/historical_2016_2019.xlsx\", index_col='Names Date')\n",
    "stock_names = log_returns_df.columns   # this is just simple returns, not log -- but whatevs\n",
    "df_shape = (log_returns_df.shape)\n",
    "print(f\"There are {df_shape[0]} rows and {df_shape[1]} columns in the dataset.\")\n",
    "print(f\"Data timeperiod covers: {log_returns_df.index[0]} to {log_returns_df.index[-1]}\")\n",
    "\n",
    "ticker_names = log_returns_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def XY_ranking(G):\n",
    "    G1 = nx.Graph()\n",
    "    weight_map = lambda w: 1+w\n",
    "    for u,v,d in G.edges(data=True):\n",
    "        G1.add_edge(u,v,weight=weight_map(d['weight']))\n",
    "    #deg= pd.DataFrame.from_dict(dict(G1.degree(weight='weight')), orient='index', columns = ['D'])\n",
    "    #deg_ranking = deg['D'].argsort().argsort()\n",
    "    PG_ranking = pd.Series(nx.pagerank(G1, weight='weight')).rank()  # almost identical to degree\n",
    "    EC_ranking = pd.Series(nx.eigenvector_centrality(G1, weight='weight', max_iter=1000)).rank()\n",
    "    \n",
    "    G1 = nx.Graph()\n",
    "    weight_map = lambda w: np.sqrt(2*(1-w))\n",
    "    #for u,v,d in G0_filtered.edges(data=True):\n",
    "    for u,v,d in G.edges(data=True):\n",
    "        G1.add_edge(u,v,weight=weight_map(d['weight']))\n",
    "    NE_ranking = (-pd.Series(nx.eccentricity(G1))).rank()\n",
    "    CLO_ranking = pd.Series(nx.closeness_centrality(G1, distance='weight')).rank()\n",
    "    BC_ranking = pd.Series(nx.betweenness_centrality(G1, weight='weight')).rank()\n",
    "    \n",
    "    X = (PG_ranking + BC_ranking).rank()\n",
    "    Y = (NE_ranking + CLO_ranking + EC_ranking).rank()\n",
    "    return X,Y,(X+Y).rank()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wrap the whole correlation construction into one function?\n",
    "def shrinkage_estimator(corr, shrinkage_coef):\n",
    "    shrinkage_target=np.eye(corr.shape[1])\n",
    "    return corr*(1-shrinkage_coef) + shrinkage_target*shrinkage_coef\n",
    "\n",
    "class XY_constructor:\n",
    "    def __init__(self, basket_update_frequency, rolling_window):\n",
    "        self.basket_update_frequency = basket_update_frequency\n",
    "        self.rolling_window          = rolling_window\n",
    "    \n",
    "    def get_XYs(self, data, verbose = False):\n",
    "        T, n = data.shape\n",
    "        \n",
    "        df_Xs  = pd.DataFrame(columns=ticker_names, index=data.index)\n",
    "        df_Ys  = pd.DataFrame(columns=ticker_names, index=data.index)\n",
    "        df_XYs = pd.DataFrame(columns=ticker_names, index=data.index)\n",
    "        \n",
    "        for t in range(self.rolling_window, T-1):\n",
    "            if (t - self.rolling_window)%self.basket_update_frequency == 0:\n",
    "                timestamp = time()\n",
    "                corr   = shrinkage_estimator(data.iloc[t - self.rolling_window:t].corr(), 1e-4)\n",
    "                G      = nx.from_pandas_adjacency(corr - np.diag(np.diag(corr)))\n",
    "                G      = PMFG(G).compute(tol_ratio=.03)   # do not save dense corr-network\n",
    "                X,Y,XY = XY_ranking(G)\n",
    "                timestamp = time() - timestamp\n",
    "                \n",
    "                if verbose:\n",
    "                    print('\\nRecomputing filtered network at ', data.index[t])\n",
    "                    print('Time taken: %.2f\\n' %timestamp)\n",
    "            \n",
    "            # might want to save only @ dates when the basket is rebalanced\n",
    "            df_Xs.loc[data.index[t]]  = X\n",
    "            df_Ys.loc[data.index[t]]  = Y\n",
    "            df_XYs.loc[data.index[t]] = XY\n",
    "        \n",
    "        df_Xs  = df_Xs.fillna(method='bfill')\n",
    "        df_Ys  = df_Ys.fillna(method='bfill')\n",
    "        df_XYs = df_XYs.fillna(method='bfill')\n",
    "            \n",
    "        return df_Xs, df_Ys, df_XYs\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Recomputing filtered network at  2017-01-03 00:00:00\n",
      "Time taken: 60.05\n",
      "\n",
      "\n",
      "Recomputing filtered network at  2017-04-04 00:00:00\n",
      "Time taken: 56.15\n",
      "\n",
      "\n",
      "Recomputing filtered network at  2017-07-05 00:00:00\n",
      "Time taken: 45.57\n",
      "\n",
      "\n",
      "Recomputing filtered network at  2017-10-03 00:00:00\n",
      "Time taken: 36.22\n",
      "\n",
      "\n",
      "Recomputing filtered network at  2018-01-03 00:00:00\n",
      "Time taken: 40.94\n",
      "\n",
      "\n",
      "Recomputing filtered network at  2018-04-05 00:00:00\n",
      "Time taken: 62.15\n",
      "\n",
      "\n",
      "Recomputing filtered network at  2018-07-05 00:00:00\n",
      "Time taken: 58.33\n",
      "\n",
      "\n",
      "Recomputing filtered network at  2018-10-03 00:00:00\n",
      "Time taken: 58.15\n",
      "\n",
      "\n",
      "Recomputing filtered network at  2019-01-04 00:00:00\n",
      "Time taken: 63.34\n",
      "\n",
      "\n",
      "Recomputing filtered network at  2019-04-05 00:00:00\n",
      "Time taken: 67.74\n",
      "\n",
      "\n",
      "Recomputing filtered network at  2019-07-08 00:00:00\n",
      "Time taken: 68.01\n",
      "\n",
      "\n",
      "Recomputing filtered network at  2019-10-04 00:00:00\n",
      "Time taken: 65.72\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# basket size 30, quarterly rebalance, 1y rolling window for est.\n",
    "update_freq = 63\n",
    "#rolling_window = 126\n",
    "rolling_window = 252\n",
    "\n",
    "t_back = XY_constructor(update_freq, rolling_window)\n",
    "tXs, tYs, tXYs = t_back.get_XYs(log_returns_df, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tXs.to_csv('data/X_rankings.csv', index_label='Date')\n",
    "tYs.to_csv('data/Y_rankings.csv', index_label='Date')\n",
    "tXYs.to_csv('data/XY_rankings.csv', index_label='Date')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
